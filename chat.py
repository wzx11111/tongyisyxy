import streamlit as st
from openai  import OpenAI

st.set_page_config(
    page_title="ä¸‰äºšå­¦é™¢æ™ºèƒ½åŠ©æ‰‹",
    page_icon="ğŸ¤–",
    layout="centered"
)
st.markdown("""<style>
    .stApp {
        max-width: 1000px;  /* é™åˆ¶åº”ç”¨æœ€å¤§å®½åº¦ä¸º1000åƒç´  */
        margin: 0 auto;  /* è®¾ç½®æ°´å¹³å±…ä¸­ */
    }
    
    /* éšè—Streamlité»˜è®¤çš„èœå•å’Œé¡µè„šï¼Œä½¿ç•Œé¢æ›´ç®€æ´ */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    
    /* è®¾ç½®æ ‡é¢˜å±…ä¸­æ˜¾ç¤ºï¼Œå¹¶ä½¿ç”¨æ·±ç°è“è‰² */
    h1 {
        text-align: center;
        color: #1a2a3a;
    }
    
    /* è®¾ç½®å‰¯æ ‡é¢˜æ ·å¼ï¼Œä½¿ç”¨ç°è‰²å¹¶æ·»åŠ åº•éƒ¨é—´è· */
    .subtitle {
        text-align: center;
        color: #6b7280;
        margin-bottom: 2rem;
    }
</style>""", unsafe_allow_html=True)

def create_openai_client():
    return OpenAI(
        api_key="sk-86e4675f4fbb4668b87aaeee558d8678",
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        timeout=180.0,
    )
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", 
         "content": "ä½ å¥½ï¼æˆ‘æ˜¯ä¸‰äºšå­¦é™¢çš„æ™ºèƒ½åŠ©æ‰‹ï¼ŒåŸºäºé˜¿é‡Œäº‘é€šä¹‰åƒé—®å¤§æ¨¡å‹ã€‚è¯·é—®æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"}
    ]

if "open_client" not in st.session_state:
    st.session_state.open_client = create_openai_client()

st.title("ğŸ¤– ä¸‰äºšå­¦é™¢æ™ºèƒ½èŠå¤©åŠ©æ‰‹")
st.markdown('<p class="subtitle">åŸºäºé˜¿é‡Œäº‘é€šä¹‰åƒé—®å¤§æ¨¡å‹</p>',unsafe_allow_html=True)

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("åœ¨è¿™é‡Œè¾“å…¥ä½ çš„é—®é¢˜"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    with st.chat_message("assistant"):
        with st.spinner("æ€è€ƒä¸­..."):
            try:
                response = st.session_state.openai_client.chat.completions.create(
                    model="qwen-plus",
                    messages=[
                        {"role": "system", 
                        "content": "ä½ æ˜¯ä¸‰äºšå­¦é™¢çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œè¡¨ç°å¾—å‹å¥½ã€ä¸“ä¸šä¸”ä¹äºåŠ©äººã€‚",
                        },
                        *[
                            {"role": m["role"],"content":m["content"]}
                            for m in st.session_state.messages
                        ],
                    ],
                    temperature=0.7,
                    max_tokens=2000,
                )
                ai_response = response.choices[0].message.content
                st.markdown(ai_response)
                st.session_state.messages.append(
                    {"role": "assistant", "content": ai_response}
                )
            except Exception as e:
                st.error(f"æŠ±æ­‰ï¼Œå‘ç”Ÿäº†é”™è¯¯ï¼š{str(e)}")